{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorry that it took a bit -- I was wrecked after the overnight flight but back on track now. Here's a number of papers that form a starting point. Basically, \n",
    "we want to model findings like Ijaz and Munnich&Landau found (for the domain of static topological space),\n",
    "\n",
    " but then with a method similar to Alferink&Gullberg (who look at another domain, placement verbs). \n",
    "    - nice thing about is the way they dont do general but very particular deductions\n",
    "    \n",
    "We've been using the ALCOVE model in the Kruschke paper recently, and it's (maybe) possible to extend that to second language learning, but there's also the Bilingual Lexical interactions Zhao&Li work on lexical semantics, bilingualism and neural networks which we need to look at if we were to do anything in this direction.\n",
    "\n",
    "- 2yr -3yr - converge to an adult\n",
    "- color, showed perception/conception. that for color perception was better. it was achieved via PCA on \n",
    "    - each row is a color\n",
    "    - each column is the response on the color\n",
    "- category nodes are colors\n",
    "- for us category nodes alcove model\n",
    "    - the activation nodes is whats learned to give interpretavility\n",
    "    - the two different languages should have activation languages\n",
    "    \n",
    "- not batch \n",
    "- incremental\n",
    "- 10000 examples\n",
    "- intrepretabiilty\n",
    "- usingn the same images as bowerman stimuli\n",
    "- \n",
    "# Papers\n",
    "\n",
    "  * [Linguistic and Cognitive Determinants of Lexical Acquisition in a Second Language 1986](#Ijaz)\n",
    "  * [Developmental Decline in the Acquisition of Spatial Language 2010](#Munnich&Landau)\n",
    "  \n",
    "  \n",
    "  * [French–Dutch bilinguals do not maintain obligatory semantic distinctions: Evidence from placement verbs 2014](#Alferink&Gullberg)\n",
    "  * [ALCOVE: An Exemplar-Based Connectionist Model of Category Learning](#Kruschke)\n",
    "  * [Bilingual lexical interactions in an unsupervised neural network model](#Zhao&Li)\n",
    "  * [Why Some Spatial Semantic Categories Are Harder to Learn than Others The Typological Prevalence Hypothesis 2009](#Genter&Bowerman)\n",
    "\n",
    "Papers:\n",
    "Qs\n",
    "\n",
    "#####  French–Dutch bilinguals do not maintain obligatory semantic distinctions: Evidence from placement verbs 2014 <a id=\"#Alferink&Gullberg\"></a>\n",
    "\n",
    "A core issue in acquisition and bilingualism studies is to improve our understanding of “the influence of a person’s knowledge of one language on that person’s knowledge or use of another language” often labelled as transfer or crosslinguistic influence\n",
    "- Note that we are considering situations in which there is simple support from below on a flat surface.\n",
    "- \n",
    "\n",
    "\n",
    "---\n",
    "##### Bilingual lexical interactions in an unsupervised neural network model <a id=\"#Zhao&Li\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "##### Developmental Decline in the Acquisition of Spatial Language 2010 <a id=\"#Munnich&Landau\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##### Linguistic and Cognitive Determinants of Lexical Acquisition in a Second Language 1986  <a id=\"#Ijaz\"></a>\n",
    "Write down three hypothesis\n",
    "\tUnderstand the experiment and metric they used better\n",
    "\n",
    "---\n",
    "##### [ALCOVE: An Exemplar-Based Connectionist Model of Category Learning](http://psych.indiana.edu/tradition/Kruschke_1992.pdf) <a id=\"#Kruschke\"></a>\n",
    "\n",
    "ALCOVE (Attention Learning Covering Map)\n",
    "\tGeneralized Context Model with error driven learning assumptions\n",
    "by allowing continuous dimensions and including ex- plicit dimensional attention learning\t\t\n",
    "the goal of ALCOVE is not to discover new (hidden-layer) representations after lengthy training but rather to model the course of learning itself by determining which dimensions of the given representation are most relevant to the task and how strongly to associate exemplars with categories.\t\t\t\t\t\n",
    "ALCOVEdoes not suffer the catastrophic retroac- tive interference seen in standard back propagation (McClos- key & Cohen, 1989; Ratcliff, 1990).  \n",
    "\n",
    "\n",
    "- Gates for the input: Before training begins, the model is initialized with equal atten- tion strengths on all dimensions, and as training proceeds, the model learns to allocate more attention to relevant dimensions and less to irrelevant dimensions.\n",
    "- For example, if the input dimensions are perceived size and perceived brightness, and one of the training stimuli has scale values of size = 10 and brightness = 5, then there is a hidden node placed at the position (10, 5)\n",
    "-  In a more complicated version, discussed at the end of the article, hidden nodes are scattered randomly across the space, forming a covering map of the input space. \n",
    "- The specificity constant, c, determines the overall width of the acti- vation profile. Large specificities imply very rapid similarity decrease and hence a narrow activation profile, whereassmall specificities correspond to wide profiles. Psychologically, the specificity of a hidden node indicates the overall cognitivedis- criminability or memorability of the corresponding exemplar.\n",
    "- The region of stimulus space that significantly activates a hid- den node will be loosely referred to as that node's receptive field.\n",
    "-  In ALCOVE,the dimensions most relevant to the category distinction learn larger attention strengths, and the less relevant dimensions learn smaller attention strengths.\n",
    "- ?? Because the hidden node is activated only by stimuli in a restricted region of input space near its corresponding exemplar, the connection weight is called the association weight between the exemplar and the category. -?>\n",
    "- output layer, or category nodes\n",
    "\\begin{equation}\n",
    "a_k^{out} =  \\sum_{hid j}(W_kj*a_j^{hid}) \\\\\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Inverted indexing for cross-lingual nlp, ACL 2015 Video](http://techtalks.tv/talks/inverted-indexing-for-cross-lingual-nlp/61852/)\n",
    "[Paper](http://www.aclweb.org/anthology/P15-1165)\n",
    "\n",
    "* So they use wikipedia article which gets matched up with a wikipedia concept to get parallel documents in different languages. They then make an inverted document index and use SVD for dimensionality reduction \n",
    "* 100,000 wiki concepts in 52 languages. \n",
    "* 40 dimensions for SVD\n",
    "* Simple and fast way to obtain interlingual representation good for low resource languages\n",
    "\n",
    "---\n",
    "\n",
    "##### [Why Some Spatial Semantic Categories Are Harder to Learn than Others The Typological Prevalence Hypothesis 2009, Dedre Genter, Melissa Bowerman](http://spatiallearning.org/publications_pdfs/gentner_bowerman_2009.pdf) <a id=\"Genter&Bowerman\"></a>\n",
    " \n",
    "* (a)\"support from below\" (e.g.,cup on table, man on roof),\n",
    "* (b)\"clingy attachment\" (e.g.,bandaid on leg, raindrops on window), \n",
    "* (c) \"hanging against\" (e.g.,picture on wall, coat on banister), \n",
    "* (d)\"point-to-point attachment\" (e.g., apple on branch, string on balloon),  \n",
    "* (e) \"encirclement with contact\" (e.g.,ribbon on candle, ring on finger),and \n",
    "* (f)\"full containment\" (e.g.,apple in bowl, rabbit in\n",
    "\n",
    "<img  src=\"Screen Shot 2016-01-04 at 12.37.36 AM.png\"/>\n",
    "\n",
    "**The Typological Prevalence Hypothesis:** All else being equal, within a given domain, t h e more frequently a given way of categorizing is found in the languages of the world, the more natural it is for human cognizers, hence the easier it will be for children to learn.\n",
    "\n",
    "Typological Prevalence hypothesis, semantic categories that are crosslinguistically common reflect a way of partitioning a domain that is conceptually relatively \"natural\" for human cognizers\n",
    "\n",
    "###### Experiment Setup\n",
    "\n",
    "* Native speakers of Dutch and English. \n",
    "* In each language there were ten children in each of five age groups: 2-, 3-, 4-, 5-, and 6-year-olds, as well as a group of 10 adults.\n",
    "* 32 key stimulus configurations \n",
    "* Thus, each child received 40 stimuli, as well as 4 practice items?\n",
    "\n",
    "###### Results\n",
    "1. English learners acquired their single term (on) for the ON category much earlier than Dutch learners acquired their three terms (op, om, and aan).\n",
    "2. Both Dutch and English children acquired the IN category early and at about the same time, also consistent with the hypothesis. The lack of language differences in the IN cat- egory helps dispel the possible concern that the differences seen in the two ON syste~lls miglit reflect a mismatch between the two populations in their overall level of language development.\n",
    "3. Within Dutch, the crosslinguisticallyrare categories associated with the prepositions aan (\"tenuous support\") and om (encirclement with contact) are acquired much later than the crosslinguistically more common category associated with op (\"solid support\").\n",
    "4. The advantage of English over Dutch was greatest for iteins in semantic subclasses that are rarely singled out for distinctive labeling in the world's languages-the categories associ- ated with aan and om in Dutch.\n",
    "5. When Dutch children made errors in encoding ON relations, they limited their choices to other prepositions of contact and support, especially tending to overextend op to situations that adults would describe with aan or om. This is a rather strong indication of the naturalness of the extended ON category,because if the Dutch children were simply using high-frequency spatial prepositions when they were uncertain, they would have shown a broader set of substi- tution errors, including use of the early-learned and highly frequent preposition in.\n",
    "\n",
    "###### is it just cause on is Simpler or not?\n",
    "* But if conceptual naturalness is related to crosslinguistic prevalence, as we propose, then Dutch children should take longer than English children to learn their ON system because the Dutch pattern is rare and the English pattern is com- mon. - QS ABOUT DIFFICULTY OF THE THING LEARNING\n",
    "* For example, children initially often underextend words, e.g., using up only when asking to be picked up in someone's arms rather than for a full range of \"motion upward\" (Gentner, 1982).\n",
    "* There is no reason, then, to assume that learning a single large ON category is necessarily easier than learning three sinaller categories.\n",
    "* In light of R. Brown's (1973)landmark study of the acquisition of the 14 grammatical morphemes acquired earliest in English (among them, the prepositions in and on). His analysis of the recorded utterances of three children (Adam, Eve, and Sarah) showed a highly stable order of acquisition, which was not correlated with the frequency of these mor- phemes in parental speech to the children. Brown concluded that at the extremely high levels of frequency associated with grammatical morphemes, frequency is not a determining factor in the order of acquisition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this paper, we use a computational model to study both the acquisition of color terms and behavior on a non-verbal color discrimination task.\n",
    "\n",
    "-  These effects disappear in a verbal-interference condition, indicating this is a linguistic influence on lower-level processing. ??\n",
    "- Harder discrimination task? is near\n",
    "- toy languages, how it learns in learning\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
